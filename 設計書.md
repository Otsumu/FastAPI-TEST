# CPUモニタリングシステム 設計書

## 1. 設計方針と検証

### 設計方針
「高速検索」「メモリ負荷軽減」を最優先的に考慮したCPUモニタリングシステム設計

### 設計判断と根拠

#### 事前集計方式を採用 → 表示時の検索処理を高速化

> **根拠**  
> 表示時に毎回集計計算をするより、事前に統計値を計算しておくことで、画面表示時の検索処理を大幅に高速化

#### 全カラムINTEGER型 → 検索速度とメモリ効率を最優先

> **根拠**  
> REALも検討したが完全一致検索が困難なことに加え、INT型が4バイトなのに対し、8バイトの容量を要するため、メモリ効率も考慮し全型INTEGERを採用した

#### 2テーブル構成 → 生データと加工した集計データに分離し検索負荷を軽減

> **根拠**  
> 生データテーブル(cpu_load)は収集したデータのみを保存、集計データテーブル(cpu_load_summary)には事前集計した統計値データを保存。<br>
データの役割を明確に分離することで各テーブルの検索負荷を軽減し、目的に応じた最適な検索性能を実現

### 妥当性の検証

#### 集計処理の動作確認
- 76件の集計データが正常動作(10分間隔)
- 他28件、16件、4件の各時間間隔(30分、1時間、1日)集計も正常実行

#### 時間間隔別の集計の正確性
- INTERVAL_TYPE 0=10分、1=30分、2=1時間、3=1日の各間隔で適切にデータをグループ化し集計処理

#### CPU毎統計値の算出確認
- 4CPU(cpu_id 0、1、2、3) それぞれで算出した平均、最大、最小、件数を計算しcpu_load_summaryテーブルに保存

## 2. システム概要

### 目的
- CPUの使用率をリアルタイムで閲覧ができる
- 時間間隔別の集計データ、並びにユーザーが任意の期間で選択したデータの参照も可能

### 構成
```
データ挿入/収集 → データ蓄積 → データ集計 → データ表示
InsertMetrics   → cpu_load   → CreateSummary → API/Frontend
```

## 3. データベース設計
生データと加工データで効率的に可視化できるように設計

### 生データテーブル（cpu_load）

```sql
CREATE TABLE cpu_load (
    id INTEGER PRIMARY KEY,
    timestamp INTEGER NOT NULL,
    cpu_id INTEGER,
    utilization INTEGER
);
```

#### 設計根拠
検索速度とメモリ効率を重視したため全カラム「INTEGER」を採用

- **timestamp** … UNIX秒（整数）で時系列処理を高速化
- **cpu_id** … CPUの識別番号（0,1,2,3...最大15）なので整数が自然
- **utilization** … CPU使用率（0-100%）は整数で十分な精度

#### 検証
- **現在の構成**: 4CPU × 8,640回/日 = 34,560件/日
- **将来の構成**: 16CPU × 8,640回/日 = 138,240件/日
- **月間最大**: 約400万件（138,240×30日） → 将来拡張があるのであればindexを検討

※ 8640回は1日=24h×60分=1440分、1440分×6回/分=8640回  
※ 収集データは10秒間隔なので1分間に6回の収集で計算

### 集計テーブル（cpu_load_summary）

```sql
CREATE TABLE cpu_load_summary (
    id INTEGER PRIMARY KEY,
    bucket_timestamp INTEGER,
    interval_type INTEGER,
    cpu_id INTEGER,
    avg_utilization INTEGER,
    max_utilization INTEGER,
    min_utilization INTEGER,
    sample_count INTEGER
);
```

#### 集計実行タイミング
- **初期実装(現在)**: 手動実行(create_summary_data()メソッドで実行)
- **将来計画**: 定期バッチ処理(タスクスケジューラーを使用し１時間毎に自動実行)

#### 集計処理の実装方法

1. cpu_loadテーブルから生データを取得
2. INTERVAL_TYPEの時間間隔でデータをグループ化
3. 各グループで統計値を計算（平均、最大、最小、件数）
4. cpu_load_summaryテーブルに結果を保存

#### 具体例：10分間隔集計の場合
- **対象時間**: 実際のデータ範囲を10分間隔で分割
- **取得データ**: cpu_loadテーブルの各10分間のレコード
- **計算結果**: データ範囲に応じた期間数 × CPU数の集計データを作成(10分間隔の場合76件)
- **統計値**: 各期間、各CPUの平均、最大、最小、件数を計算

#### 設計根拠
検索速度とメモリ効率を重視したためcpu_load同様全カラム「INTEGER」を採用

- **事前集計方式** … 各INTERVAL_TYPEの平均値を事前に計算、リアルタイムでの表示を高速化
- **bucket_timestamp** … 集計期間の開始時刻
- **interval_type** … 0 = 10分、1 = 30分、2 = 1時間、3 = 1日　の4パターンを設定

## 4. クラス設計

### ConnectMetrics（データベース接続・テーブル設計）
**役割**: データベース初期化、テーブル作成

### InsertMetrics（データ挿入、収集）
**役割**: CPUメトリクス(cpu_load)の収集・挿入

### CreateSummary（集計処理）
**役割**: 時間間隔別の事前集計

## 5. インデックス戦略

今回のような複合インデックスでは、インデックスのサイズが大きくなる傾向があり、特に更新時にインデックスの更新コストが増加する可能性が予想される。

そのため、3のデータベース設計内と重複しますが、将来的にデータ数が「最大400万件に増加する」ことを考慮すると、<br>
検索頻度の高いと思われるcpu_load_summaryにはインデックスを貼付しておいた方が良いと判断。

```sql
CREATE INDEX index_bucket_type_cpu_id ON cpu_load_summary(
    bucket_timestamp, 
    interval_type, 
    cpu_id
);
```

cpu_loadテーブルは10秒毎にデータを取得しているため更新頻度が高く、逆に検索頻度は集計処理時のみと低いので、インデックスを貼付しないと判断した。

### インデックス戦略比較

#### インデックスなしの場合
- **テーブル**: cpu_load_summary
- **対象クエリ**: サマリー検索
- **効果**: 400万件すべて検索するためマシンに負荷がかかる

#### インデックスありの場合
- **テーブル**: cpu_load_summary
- **インデックス**: bucket_timestamp, interval_type, cpu_id
- **対象クエリ**: サマリー検索
- **効果**: 全件検索不要、検索速度の高速化

## 6. RESTfulAPI仕様	

### 設計原則									
- HTTPメソッド：GET（データ取得）、POST（データ投入・処理実行）のみ使用									
- レスポンス形式：JSON形式									
- エラーハンドリング：適切なエラーメッセージ									
- パラメータ：クエリパラメータを適切に使用			

### エンドポイント一覧									
#### ===== メトリクス関連 =====									
GET /api/metrics									
- 目的: 生データ取得									
- パラメータ：mode (string、default："realtime")									
- レスポンス：全CPUの生データ									
                                    
POST /api/metrics									
- 目的：新規メトリクスデータ投入  									
- リクエストボディ：JSONメトリクスデータ									
- レスポンス：投入結果ステータス（成功/エラー）									
                                    
#### ===== 集計データ関連 =====									
GET /api/summary									
- 目的: 集計データ取得									
- パラメータ:									
start_timestamp (int, required)：開始時刻、&nbsp; 								
end_timestamp (int, required)：終了時刻、&nbsp;									
cpu_id (int, optional)：CPU指定、&nbsp;									
interval_type (int, optional)：集計間隔指定									
- **レスポンス: 指定条件の集計データ									
                                    
POST /api/summary									
- 目的: 集計処理実行									
- パラメータ:									
seconds (int, optional, default: 600)：集計間隔秒数、&nbsp;								
index (int, optional, default: 0)：集計間隔インデックス (0=10分, 1=30分, 2=1時間, 3=1日)								
- レスポンス: 集計処理結果ステータス(成功/エラー)									
                                    
### レスポンス形式									
成功レスポンス例									
```	
json								
{									
  "status": "success",									
  "data": {									
    "cpu0": [									
      {"timestamp": 1750922781, "utilization": 45},									
      {"timestamp": 1750922841, "utilization": 52}									
    ]									
  }									
}									
```                                   
エラーレスポンス例									
```	
json								
{									
  "status": "error",									
  "message": "データ取得に失敗しました",									
}									
```                                    
### FastAPIスケルトン実装	
```								
python									
from fastapi import FastAPI									
from fastapi.staticfiles import StaticFiles									
from typing import Optional																		
                                    
app = FastAPI(title="fastapi-test")									
```                                    

### 静的ファイル配信					
```				
app.mount("/frontend/static", StaticFiles(directory="../frontend/static"), name="static")									
```

### ===== メトリクス関連 =====									
```                                   
@app.get("/api/metrics")									
def get_metrics(mode: str = "realtime"):									
    """生データ取得"""									
    # 実装時は既存のInsertMetrics.get_metrics()を使用									
```
```                                        
@app.post("/api/metrics")									
def post_metrics(json_data: dict):									
    """メトリクスデータ投入"""									
    # 実装時は既存のInsertMetrics.insert_cpu_utilization()を使用									
```                                        
### ===== 集計データ関連 =====									
```                                    
@app.get("/api/summary")									
def get_summary_data(									
    start_timestamp: int, 									
    end_timestamp: int,									
    cpu_id: Optional[int] = None, 									
    interval_type: Optional[int] = None									
):									
    """集計データ取得"""									
    # 実装時は既存のCreateSummary.get_summary_data()を使用									
```
```
@app.post("/api/summary")									
def create_summary(seconds: int = 600, index: int = 0):									
    """集計処理実行"""									
    # 実装時は既存のCreateSummary.create_summary_data()を使用									
```                                    
### 実装時の統合方法									
既存の server.py から本スケルトンへの統合手順：	
							
1.既存インポート追加									
```
python									
from insert import InsertMetrics									
from summary import CreateSummary									
```
2.既存インスタンス作成									
```
python									
db = InsertMetrics()									
summary_db = CreateSummary()									
```			

## 7. 結論

### 設計の成果
本CPUモニタリングシステムは「高速検索」「メモリ負荷軽減」を最優先とした設計により、以下の成果を実現しました：

- **実際の動作確認済み**: 76件10分間隔集計をはじめ、全時間間隔での正常動作を確認
- **性能要件の充足**: 将来400万件近くのデータ増加にも対応可能な設計
- **実用的なアーキテクチャ**: 事前集計方式とテーブル分離による高速検索の実現

### 設計の信頼性
実際の検証結果に基づいた確実性のある設計として、要求されたCPUモニタリング機能を満たすシステムを構築しました。